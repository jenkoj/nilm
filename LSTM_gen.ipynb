{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-gen",
      "provenance": [],
      "authorship_tag": "ABX9TyMej4PvP65qsLng7TnQKWA4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqUfHWgtJxtu"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools \n",
        "import pyts\n",
        "from pyts.approximation import PiecewiseAggregateApproximation\n",
        "\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.layers import Convolution2D,Conv2D, Dense,Dropout, Flatten, Activation, MaxPooling2D, Input, Conv1D, GlobalAveragePooling1D, TimeDistributed, GRU, LSTM\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYrWi4wMKCWE"
      },
      "source": [
        "def plot_confusion_matrix_norm(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    This function prints and plots the confusion matrix.\n",
        "\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "\n",
        "    if normalize:\n",
        "\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        cm = np.around(cm, decimals=2)\n",
        "\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "\n",
        "        print(\"Normalized confusion matrix\")\n",
        "\n",
        "    else:\n",
        "\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "\n",
        "        plt.text(j, i, cm[i, j],\n",
        "\n",
        "                 horizontalalignment=\"center\",\n",
        "\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5_dMKrLKHJt"
      },
      "source": [
        "def LSTM_3D(X_train, num_classes, lr = 0.0001):\n",
        "\n",
        "    input_a = Input(shape = X_train.shape[1: ])\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(16, (7, 7), activation='relu', padding='same'))(input_a)\n",
        "    x = TimeDistributed(Convolution2D(16, (7, 7), activation='relu', padding='same'))(x)\n",
        "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
        "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
        "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
        "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
        "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
        "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
        "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
        "    x = Dropout(0.10)(x)\n",
        "\n",
        "    out = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
        "    out = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(out)\n",
        "        # out = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(out)\n",
        "        # out = Dropout(0.60)(out)\n",
        "    out = TimeDistributed(Flatten())(out)\n",
        "    out = LSTM(16, return_sequences=False, unroll=False, dropout=0.2)(out)  # dropout=0.6\n",
        "    prediction = Dense(num_classes, activation='softmax')(out)\n",
        "    model = keras.models.Model(inputs=input_a, outputs=prediction)\n",
        "    adam = optimizers.Adam(lr = lr)\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leuzbmn-KODX"
      },
      "source": [
        "def basic_cnn_functional(X_train, num_classes, lr = 0.0001):\n",
        "    \n",
        "    input_a = Input(shape = X_train.shape[1: ])\n",
        "    \n",
        "    x = Convolution2D(16, (7, 7), activation='relu', padding='same')(input_a)\n",
        "    x = Convolution2D(16, (7, 7), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "    x = Dropout(0.10)(x)\n",
        "\n",
        "    out = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    out = Convolution2D(16, (3, 3), activation='relu', padding='same')(out)\n",
        "        # out = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(out)\n",
        "        # out = Dropout(0.60)(out)\n",
        "    out = Flatten()(out)\n",
        "    # dense layer with 50 neurons\n",
        "    dense = Dense(64, activation = 'relu')(out)\n",
        "    # final layer with 10 neurons to classify the instances\n",
        "    output = Dense(num_classes, activation = 'softmax')(dense)\n",
        "    \n",
        "    adam = optimizers.Adam(lr = lr)\n",
        "    model = keras.models.Model(inputs=input_a, outputs=output)\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT1vwq7-KOtB"
      },
      "source": [
        "#LOAD DATASET\n",
        "file_name = \"ukdale_gen_GAF_13m_100S5X_14A40320N_AVG-Y_R12_S80-20\"\n",
        "\n",
        "#read the file\n",
        "path = str(pathlib.Path().resolve())\n",
        "\n",
        "path_data = f\"{path}\"\"/data/\"f\"{file_name}\"\"/\"f\"{file_name}\"\".hdf5\"\n",
        "\n",
        "file = h5py.File(path,\"r+\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IzkR99fKbRe"
      },
      "source": [
        "#fetch array of appliances\n",
        "enc_appliances = np.array(file[\"classes/appliances\"])\n",
        "appliances = [n.decode(\"utf-8\") for n in enc_appliances]\n",
        "num_of_classes = file[\"classes/appliances\"].shape[0]\n",
        "#manualy_selected_appliances.remove(\"microwave\")\n",
        "\n",
        "#fetch array of weights\n",
        "#class_weights = np.array(file[\"classes/weights\"])\n",
        "#class_weights = np.delete(class_weights,5)\n",
        "print(appliances)\n",
        "\n",
        "#print(class_weights)\n",
        "\n",
        "# #read train and label data\n",
        "#data_train = np.array(file['data/train']['gasf'])\n",
        "\n",
        "labels_test = np.array(file['labels/test']['gaf'])\n",
        "labels_train = np.array(file['labels/train']['gaf'])\n",
        "\n",
        "X_train = np.array(file['data/train']['gasf'])\n",
        "X_test = np.array(file['data/test']['gasf'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S-dku5WKpQx"
      },
      "source": [
        "#read the file\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/NILM/GAF_DS_UNZIPPED/\"f\"{file_name}\"\"/\"f\"{file_name}\"\".hdf5\"\n",
        "train_gen = HDF5ImageGenerator(\n",
        "    src= path,\n",
        "    X_key=\"data/train/gasf\",\n",
        "    y_key=\"labels/train/gaf\",\n",
        "    classes_key=\"classes/appliances\",\n",
        "    labels_encoding=\"hot\",\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        "    num_classes=num_of_classes,\n",
        "    mode=\"train\"\n",
        "    )\n",
        "\n",
        "test_gen = HDF5ImageGenerator(\n",
        "    src= path,\n",
        "    scaler=False,\n",
        "    X_key=\"data/test/gasf\",\n",
        "    y_key=\"labels/test/gaf\",\n",
        "    classes_key=\"classes/appliances\",\n",
        "    labels_encoding=\"hot\",\n",
        "    shuffle=False,\n",
        "    batch_size=32,\n",
        "    num_classes=num_of_classes,\n",
        "    mode=\"train\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqA9NwOqKrb5"
      },
      "source": [
        "model = LSTM_3D(data,num_of_classes,lr= 0.00002)\n",
        "\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    verbose=2,\n",
        "    epochs=10\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE9cd_A9KwzC"
      },
      "source": [
        "path_model1 = path+\"/models/model1\"\n",
        "model.save(path_model1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}