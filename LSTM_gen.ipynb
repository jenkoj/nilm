{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: pyts in /opt/conda/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.3.0 in /opt/conda/lib/python3.9/site-packages (from pyts) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.9/site-packages (from pyts) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.9/site-packages (from pyts) (1.19.5)\n",
      "Requirement already satisfied: numba>=0.48.0 in /opt/conda/lib/python3.9/site-packages (from pyts) (0.54.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (4.28.2)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.9/site-packages (from albumentations) (0.18.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.9/site-packages (from albumentations) (4.5.4.60)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.9/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (0.37.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (1.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.11.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn pyts matplotlib albumentations h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install cudnn=8.1 cudatoolkit=11.2 --yes --quiet -c nvidia -c defaults\n",
    "!pip install tensorflow==2.5 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_gen.ipynb  LSTM.ipynb  \u001b[0m\u001b[01;34mmodels\u001b[0m/  README.md\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WqUfHWgtJxtu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools \n",
    "import pyts\n",
    "from pyts.approximation import PiecewiseAggregateApproximation\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.layers import Convolution2D,Conv2D, Dense,Dropout, Flatten, Activation, MaxPooling2D, Input, Conv1D, GlobalAveragePooling1D, TimeDistributed, GRU, LSTM\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AYrWi4wMKCWE"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_norm(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    This function prints and plots the confusion matrix.\n",
    "\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        cm = np.around(cm, decimals=2)\n",
    "\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "\n",
    "        print(\"Normalized confusion matrix\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "\n",
    "        plt.text(j, i, cm[i, j],\n",
    "\n",
    "                 horizontalalignment=\"center\",\n",
    "\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h5_dMKrLKHJt"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (343522660.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5753/343522660.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    x = TimeDistributed(Convolution2D(16, (7, 7), activation='relu', padding='same'))(input_a) //\u001b[0m\n\u001b[0m                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def LSTM_3D(X_train, num_classes, lr = 0.0001):\n",
    "\n",
    "    input_a = Input(shape = X_train.shape[1: ])\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(16, (7, 7), activation='relu', padding='same'))(input_a) //\n",
    "    x = TimeDistributed(Convolution2D(16, (7, 7), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = Dropout(0.10)(x)\n",
    "\n",
    "    out = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
    "    out = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(out)\n",
    "        # out = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(out)\n",
    "        # out = Dropout(0.60)(out)\n",
    "    out = TimeDistributed(Flatten())(out)\n",
    "    out = LSTM(16, return_sequences=False, unroll=False, dropout=0.2)(out)  # dropout=0.6 #return sequences = True\n",
    "    prediction = Dense(num_classes, activation='softmax')(out)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_a, outputs=prediction)\n",
    "    adam = optimizers.Adam(lr = lr)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_3D_V56(X_train, num_classes, lr = 0.0001):\n",
    "    \n",
    "    input_a = Input(shape = X_train.shape[1: ])\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(input_a)\n",
    "    x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    \n",
    "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(16, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(8, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(8, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = Dropout(0.10)(x)\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    #out = Dropout(0.10)(out)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    x = LSTM(32, return_sequences=True, unroll=False, dropout=0.1)(x)  # dropout=0.6\n",
    "    out = LSTM(32, return_sequences=False, unroll=False, dropout=0.1)(x)\n",
    "    \n",
    "    prediction = Dense(num_classes, activation='softmax')(out)\n",
    "    model = keras.models.Model(inputs=input_a, outputs=prediction)\n",
    "    adam = optimizers.Adam(learning_rate = lr)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leuzbmn-KODX"
   },
   "outputs": [],
   "source": [
    "def basic_cnn_functional(X_train, num_classes, lr = 0.0001):\n",
    "    \n",
    "    input_a = Input(shape = X_train.shape[1: ])\n",
    "    \n",
    "    x = Convolution2D(16, (7, 7), activation='relu', padding='same')(input_a)\n",
    "    x = Convolution2D(16, (7, 7), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.10)(x)\n",
    "\n",
    "    out = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    out = Convolution2D(16, (3, 3), activation='relu', padding='same')(out)\n",
    "        # out = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(out)\n",
    "        # out = Dropout(0.60)(out)\n",
    "    out = Flatten()(out)\n",
    "    # dense layer with 50 neurons\n",
    "    dense = Dense(64, activation = 'relu')(out)\n",
    "    # final layer with 10 neurons to classify the instances\n",
    "    output = Dense(num_classes, activation = 'softmax')(dense)\n",
    "    \n",
    "    adam = optimizers.Adam(lr = lr)\n",
    "    model = keras.models.Model(inputs=input_a, outputs=output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RT1vwq7-KOtB"
   },
   "outputs": [],
   "source": [
    "#LOAD DATASET\n",
    "file_name = \"refit_gen_GAF_13m_100S5X_22A147955_R12_S80-20\"\n",
    "\n",
    "#read the file\n",
    "path = str(pathlib.Path().resolve())\n",
    "\n",
    "path_data = f\"{path}\"\"/data/\"f\"{file_name}\"\"/\"f\"{file_name}\"\".hdf5\"\n",
    "\n",
    "file = h5py.File(path_data,\"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/Untitled Folder/nilm'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = file[\"data/train/gaf\"][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100, 100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0IzkR99fKbRe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['breadmaker', 'toaster', 'tumble dryer', 'audio system', 'food processor', 'fridge', 'games console', 'fridge freezer', 'kettle', 'broadband router', 'appliance', 'washer dryer', 'television', 'electric space heater', 'fan', 'dish washer', 'pond pump', 'microwave', 'unknown', 'computer', 'washing machine', 'dehumidifier']\n"
     ]
    }
   ],
   "source": [
    "#fetch array of appliances\n",
    "enc_appliances = np.array(file[\"classes/appliances\"])\n",
    "appliances = [n.decode(\"utf-8\") for n in enc_appliances]\n",
    "num_of_classes = file[\"classes/appliances\"].shape[0]\n",
    "#manualy_selected_appliances.remove(\"microwave\")\n",
    "\n",
    "#fetch array of weights\n",
    "#class_weights = np.array(file[\"classes/weights\"])\n",
    "#class_weights = np.delete(class_weights,5)\n",
    "print(appliances)\n",
    "\n",
    "#print(class_weights)\n",
    "\n",
    "# #read train and label data\n",
    "#data_train = np.array(file['data/train']['gasf'])\n",
    "X_test = np.array(file['data/train']['gaf'])\n",
    "y_test = np.array(file['labels/train']['gasf'])\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_of_classes)\n",
    "# labels_test = np.array(file['labels/test']['gasf'])\n",
    "labels_train = np.array(file['labels/train']['gasf'])\n",
    "\n",
    "# X_train = np.array(file['data/train']['gaf'])\n",
    "# X_test = np.array(file['data/test']['gaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 26.012705798138867, 1: 1.8754548034990839, 2: 5.492291997279528, 3: 4.826316488478651, 4: 9.412004662004662, 5: 1.2618845058684631, 6: 46.5297695262484, 7: 0.19394232924525281, 8: 0.3200400713357846, 9: 3.6645741945242776, 10: 8.34245867768595, 11: 28.60271546635183, 12: 0.20889115626706523, 13: 8.845016429353779, 14: 330.36136363636365, 15: 2.1089139076690944, 16: 2.0738315356959425, 17: 0.7184892641069239, 18: 2.748430645893208, 19: 0.3211445160264058, 20: 1.6472768069626709, 21: 13.484137291280149}\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight=\"balanced\", classes = np.unique(labels_train), y=labels_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5S-dku5WKpQx"
   },
   "outputs": [],
   "source": [
    "#read the file\n",
    "\n",
    "train_gen = HDF5ImageGenerator(\n",
    "    src= path_data,\n",
    "    X_key=\"data/train/gaf\",\n",
    "    y_key=\"labels/train/gasf\",\n",
    "    classes_key=\"classes/appliances\",\n",
    "    labels_encoding=\"hot\",\n",
    "    shuffle=True,\n",
    "    batch_size=64,\n",
    "    num_classes=num_of_classes,\n",
    "    mode=\"train\"\n",
    "    )\n",
    "\n",
    "#test_gen = HDF5ImageGenerator(\n",
    "#    src= path,\n",
    "#    scaler=False,\n",
    "#    X_key=\"data/test/gasf\",\n",
    "#    y_key=\"labels/test/gaf\",\n",
    "#    classes_key=\"classes/appliances\",\n",
    "#    labels_encoding=\"hot\",\n",
    "#    shuffle=False,\n",
    "#    batch_size=32,\n",
    "#    num_classes=num_of_classes,\n",
    "#    mode=\"train\"\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "id": "vqA9NwOqKrb5",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/150\n",
      "2272/2272 - 192s - loss: 2.8981 - accuracy: 0.0903\n",
      "Epoch 2/150\n",
      "2272/2272 - 191s - loss: 2.5357 - accuracy: 0.2278\n",
      "Epoch 3/150\n",
      "2272/2272 - 190s - loss: 2.2005 - accuracy: 0.2903\n",
      "Epoch 4/150\n",
      "2272/2272 - 190s - loss: 1.9795 - accuracy: 0.3087\n",
      "Epoch 5/150\n",
      "2272/2272 - 190s - loss: 1.8231 - accuracy: 0.3386\n",
      "Epoch 6/150\n",
      "2272/2272 - 190s - loss: 1.6950 - accuracy: 0.3669\n",
      "Epoch 7/150\n",
      "2272/2272 - 190s - loss: 1.5888 - accuracy: 0.3914\n",
      "Epoch 8/150\n",
      "2272/2272 - 190s - loss: 1.4992 - accuracy: 0.4040\n",
      "Epoch 9/150\n",
      "2272/2272 - 190s - loss: 1.4280 - accuracy: 0.4169\n",
      "Epoch 10/150\n",
      "2272/2272 - 190s - loss: 1.3563 - accuracy: 0.4265\n",
      "Epoch 11/150\n",
      "2272/2272 - 190s - loss: 1.2999 - accuracy: 0.4264\n",
      "Epoch 12/150\n",
      "2272/2272 - 190s - loss: 1.2590 - accuracy: 0.4463\n",
      "Epoch 13/150\n",
      "2272/2272 - 190s - loss: 1.2129 - accuracy: 0.4419\n",
      "Epoch 14/150\n",
      "2272/2272 - 190s - loss: 1.1763 - accuracy: 0.4523\n",
      "Epoch 15/150\n",
      "2272/2272 - 190s - loss: 1.1418 - accuracy: 0.4612\n",
      "Epoch 16/150\n",
      "2272/2272 - 190s - loss: 1.1093 - accuracy: 0.4631\n",
      "Epoch 17/150\n",
      "2272/2272 - 190s - loss: 1.0820 - accuracy: 0.4704\n",
      "Epoch 18/150\n",
      "2272/2272 - 190s - loss: 1.0520 - accuracy: 0.4807\n",
      "Epoch 19/150\n",
      "2272/2272 - 191s - loss: 1.0270 - accuracy: 0.4865\n",
      "Epoch 20/150\n",
      "2272/2272 - 190s - loss: 1.0078 - accuracy: 0.4965\n",
      "Epoch 21/150\n",
      "2272/2272 - 190s - loss: 0.9834 - accuracy: 0.4955\n",
      "Epoch 22/150\n",
      "2272/2272 - 190s - loss: 0.9602 - accuracy: 0.4959\n",
      "Epoch 23/150\n",
      "2272/2272 - 190s - loss: 0.9387 - accuracy: 0.5060\n",
      "Epoch 24/150\n",
      "2272/2272 - 190s - loss: 0.9267 - accuracy: 0.5063\n",
      "Epoch 25/150\n",
      "2272/2272 - 190s - loss: 0.9041 - accuracy: 0.5082\n",
      "Epoch 26/150\n",
      "2272/2272 - 191s - loss: 0.8851 - accuracy: 0.5220\n",
      "Epoch 27/150\n",
      "2272/2272 - 191s - loss: 0.8730 - accuracy: 0.5164\n",
      "Epoch 28/150\n",
      "2272/2272 - 191s - loss: 0.8527 - accuracy: 0.5309\n",
      "Epoch 29/150\n",
      "2272/2272 - 190s - loss: 0.8498 - accuracy: 0.5251\n",
      "Epoch 30/150\n",
      "2272/2272 - 190s - loss: 0.8356 - accuracy: 0.5312\n",
      "Epoch 31/150\n",
      "2272/2272 - 191s - loss: 0.8124 - accuracy: 0.5341\n",
      "Epoch 32/150\n",
      "2272/2272 - 190s - loss: 0.8079 - accuracy: 0.5374\n",
      "Epoch 33/150\n",
      "2272/2272 - 190s - loss: 0.7843 - accuracy: 0.5427\n",
      "Epoch 34/150\n",
      "2272/2272 - 191s - loss: 0.7807 - accuracy: 0.5434\n",
      "Epoch 35/150\n",
      "2272/2272 - 190s - loss: 0.7678 - accuracy: 0.5523\n",
      "Epoch 36/150\n",
      "2272/2272 - 191s - loss: 0.7551 - accuracy: 0.5585\n",
      "Epoch 37/150\n",
      "2272/2272 - 191s - loss: 0.7441 - accuracy: 0.5555\n",
      "Epoch 38/150\n",
      "2272/2272 - 190s - loss: 0.7325 - accuracy: 0.5589\n",
      "Epoch 39/150\n",
      "2272/2272 - 191s - loss: 0.7248 - accuracy: 0.5637\n",
      "Epoch 40/150\n",
      "2272/2272 - 190s - loss: 0.7115 - accuracy: 0.5715\n",
      "Epoch 41/150\n",
      "2272/2272 - 190s - loss: 0.7128 - accuracy: 0.5695\n",
      "Epoch 42/150\n",
      "2272/2272 - 190s - loss: 0.6945 - accuracy: 0.5801\n",
      "Epoch 43/150\n",
      "2272/2272 - 190s - loss: 0.6919 - accuracy: 0.5751\n",
      "Epoch 44/150\n",
      "2272/2272 - 191s - loss: 0.6797 - accuracy: 0.5816\n",
      "Epoch 45/150\n",
      "2272/2272 - 191s - loss: 0.6817 - accuracy: 0.5821\n",
      "Epoch 46/150\n",
      "2272/2272 - 191s - loss: 0.6613 - accuracy: 0.5908\n",
      "Epoch 47/150\n",
      "2272/2272 - 191s - loss: 0.6560 - accuracy: 0.5921\n",
      "Epoch 48/150\n",
      "2272/2272 - 191s - loss: 0.6438 - accuracy: 0.5949\n",
      "Epoch 49/150\n",
      "2272/2272 - 190s - loss: 0.6451 - accuracy: 0.5983\n",
      "Epoch 50/150\n",
      "2272/2272 - 191s - loss: 0.6399 - accuracy: 0.5981\n",
      "Epoch 51/150\n",
      "2272/2272 - 191s - loss: 0.6333 - accuracy: 0.6003\n",
      "Epoch 52/150\n",
      "2272/2272 - 191s - loss: 0.6197 - accuracy: 0.6066\n",
      "Epoch 53/150\n",
      "2272/2272 - 191s - loss: 0.6098 - accuracy: 0.6112\n",
      "Epoch 54/150\n",
      "2272/2272 - 191s - loss: 0.6151 - accuracy: 0.6096\n",
      "Epoch 55/150\n",
      "2272/2272 - 190s - loss: 0.6068 - accuracy: 0.6128\n",
      "Epoch 56/150\n",
      "2272/2272 - 190s - loss: 0.5975 - accuracy: 0.6188\n",
      "Epoch 57/150\n",
      "2272/2272 - 191s - loss: 0.6072 - accuracy: 0.6181\n",
      "Epoch 58/150\n",
      "2272/2272 - 191s - loss: 0.5898 - accuracy: 0.6200\n",
      "Epoch 59/150\n",
      "2272/2272 - 190s - loss: 0.5860 - accuracy: 0.6232\n",
      "Epoch 60/150\n",
      "2272/2272 - 190s - loss: 0.5781 - accuracy: 0.6245\n",
      "Epoch 61/150\n",
      "2272/2272 - 191s - loss: 0.5700 - accuracy: 0.6305\n",
      "Epoch 62/150\n",
      "2272/2272 - 191s - loss: 0.5688 - accuracy: 0.6305\n",
      "Epoch 63/150\n",
      "2272/2272 - 190s - loss: 0.5647 - accuracy: 0.6310\n",
      "Epoch 64/150\n",
      "2272/2272 - 190s - loss: 0.5691 - accuracy: 0.6279\n",
      "Epoch 65/150\n",
      "2272/2272 - 190s - loss: 0.5491 - accuracy: 0.6417\n",
      "Epoch 66/150\n",
      "2272/2272 - 191s - loss: 0.5467 - accuracy: 0.6374\n",
      "Epoch 67/150\n",
      "2272/2272 - 191s - loss: 0.5389 - accuracy: 0.6408\n",
      "Epoch 68/150\n",
      "2272/2272 - 190s - loss: 0.5454 - accuracy: 0.6422\n",
      "Epoch 69/150\n",
      "2272/2272 - 191s - loss: 0.5351 - accuracy: 0.6475\n",
      "Epoch 70/150\n",
      "2272/2272 - 191s - loss: 0.5326 - accuracy: 0.6445\n",
      "Epoch 71/150\n",
      "2272/2272 - 190s - loss: 0.5343 - accuracy: 0.6478\n",
      "Epoch 72/150\n",
      "2272/2272 - 190s - loss: 0.5131 - accuracy: 0.6530\n",
      "Epoch 73/150\n",
      "2272/2272 - 190s - loss: 0.5149 - accuracy: 0.6563\n",
      "Epoch 74/150\n",
      "2272/2272 - 191s - loss: 0.5261 - accuracy: 0.6500\n",
      "Epoch 75/150\n",
      "2272/2272 - 190s - loss: 0.4993 - accuracy: 0.6619\n",
      "Epoch 76/150\n",
      "2272/2272 - 191s - loss: 0.5358 - accuracy: 0.6486\n",
      "Epoch 77/150\n",
      "2272/2272 - 190s - loss: 0.4973 - accuracy: 0.6645\n",
      "Epoch 78/150\n",
      "2272/2272 - 191s - loss: 0.4989 - accuracy: 0.6642\n",
      "Epoch 79/150\n",
      "2272/2272 - 191s - loss: 0.4930 - accuracy: 0.6627\n",
      "Epoch 80/150\n",
      "2272/2272 - 191s - loss: 0.4922 - accuracy: 0.6633\n",
      "Epoch 81/150\n",
      "2272/2272 - 190s - loss: 0.4798 - accuracy: 0.6710\n",
      "Epoch 82/150\n",
      "2272/2272 - 190s - loss: 0.4901 - accuracy: 0.6656\n",
      "Epoch 83/150\n",
      "2272/2272 - 190s - loss: 0.4872 - accuracy: 0.6682\n",
      "Epoch 84/150\n",
      "2272/2272 - 190s - loss: 0.4726 - accuracy: 0.6748\n",
      "Epoch 85/150\n",
      "2272/2272 - 191s - loss: 0.4670 - accuracy: 0.6773\n",
      "Epoch 86/150\n",
      "2272/2272 - 190s - loss: 0.4817 - accuracy: 0.6739\n",
      "Epoch 87/150\n",
      "2272/2272 - 190s - loss: 0.4597 - accuracy: 0.6780\n",
      "Epoch 88/150\n",
      "2272/2272 - 190s - loss: 0.4692 - accuracy: 0.6787\n",
      "Epoch 89/150\n",
      "2272/2272 - 190s - loss: 0.4598 - accuracy: 0.6789\n",
      "Epoch 90/150\n",
      "2272/2272 - 190s - loss: 0.4547 - accuracy: 0.6817\n",
      "Epoch 91/150\n",
      "2272/2272 - 190s - loss: 0.4618 - accuracy: 0.6842\n",
      "Epoch 92/150\n",
      "2272/2272 - 190s - loss: 0.4552 - accuracy: 0.6815\n",
      "Epoch 93/150\n",
      "2272/2272 - 190s - loss: 0.4415 - accuracy: 0.6912\n",
      "Epoch 94/150\n",
      "2272/2272 - 190s - loss: 0.4501 - accuracy: 0.6799\n",
      "Epoch 95/150\n",
      "2272/2272 - 190s - loss: 0.4373 - accuracy: 0.6920\n",
      "Epoch 96/150\n",
      "2272/2272 - 190s - loss: 0.4665 - accuracy: 0.6819\n",
      "Epoch 97/150\n",
      "2272/2272 - 190s - loss: 0.4293 - accuracy: 0.6966\n",
      "Epoch 98/150\n",
      "2272/2272 - 190s - loss: 0.4342 - accuracy: 0.6954\n",
      "Epoch 99/150\n",
      "2272/2272 - 190s - loss: 0.4362 - accuracy: 0.6930\n",
      "Epoch 100/150\n",
      "2272/2272 - 190s - loss: 0.4175 - accuracy: 0.6980\n",
      "Epoch 101/150\n",
      "2272/2272 - 190s - loss: 0.4330 - accuracy: 0.6952\n",
      "Epoch 102/150\n",
      "2272/2272 - 190s - loss: 0.4236 - accuracy: 0.6972\n",
      "Epoch 103/150\n",
      "2272/2272 - 190s - loss: 0.4336 - accuracy: 0.6945\n",
      "Epoch 104/150\n",
      "2272/2272 - 191s - loss: 0.4190 - accuracy: 0.7029\n",
      "Epoch 105/150\n",
      "2272/2272 - 193s - loss: 0.4245 - accuracy: 0.6995\n",
      "Epoch 106/150\n",
      "2272/2272 - 193s - loss: 0.4065 - accuracy: 0.7054\n",
      "Epoch 107/150\n",
      "2272/2272 - 193s - loss: 0.4067 - accuracy: 0.7064\n",
      "Epoch 108/150\n",
      "2272/2272 - 193s - loss: 0.4213 - accuracy: 0.7018\n",
      "Epoch 109/150\n",
      "2272/2272 - 193s - loss: 0.3953 - accuracy: 0.7111\n",
      "Epoch 110/150\n",
      "2272/2272 - 193s - loss: 0.4078 - accuracy: 0.7079\n",
      "Epoch 111/150\n",
      "2272/2272 - 193s - loss: 0.4172 - accuracy: 0.7029\n",
      "Epoch 112/150\n",
      "2272/2272 - 193s - loss: 0.3962 - accuracy: 0.7119\n",
      "Epoch 113/150\n",
      "2272/2272 - 193s - loss: 0.3891 - accuracy: 0.7149\n",
      "Epoch 114/150\n",
      "2272/2272 - 193s - loss: 0.3939 - accuracy: 0.7093\n",
      "Epoch 115/150\n",
      "2272/2272 - 192s - loss: 0.3958 - accuracy: 0.7139\n",
      "Epoch 116/150\n",
      "2272/2272 - 193s - loss: 0.3891 - accuracy: 0.7158\n",
      "Epoch 117/150\n",
      "2272/2272 - 193s - loss: 0.3885 - accuracy: 0.7156\n",
      "Epoch 118/150\n",
      "2272/2272 - 193s - loss: 0.3988 - accuracy: 0.7130\n",
      "Epoch 119/150\n",
      "2272/2272 - 193s - loss: 0.3817 - accuracy: 0.7216\n",
      "Epoch 120/150\n",
      "2272/2272 - 193s - loss: 0.3791 - accuracy: 0.7193\n",
      "Epoch 121/150\n",
      "2272/2272 - 193s - loss: 0.3969 - accuracy: 0.7157\n",
      "Epoch 122/150\n",
      "2272/2272 - 193s - loss: 0.3755 - accuracy: 0.7238\n",
      "Epoch 123/150\n",
      "2272/2272 - 193s - loss: 0.3720 - accuracy: 0.7255\n",
      "Epoch 124/150\n",
      "2272/2272 - 193s - loss: 0.3803 - accuracy: 0.7224\n",
      "Epoch 125/150\n",
      "2272/2272 - 193s - loss: 0.3761 - accuracy: 0.7214\n",
      "Epoch 126/150\n",
      "2272/2272 - 193s - loss: 0.3695 - accuracy: 0.7261\n",
      "Epoch 127/150\n",
      "2272/2272 - 193s - loss: 0.3592 - accuracy: 0.7299\n",
      "Epoch 128/150\n",
      "2272/2272 - 193s - loss: 0.3651 - accuracy: 0.7300\n",
      "Epoch 129/150\n",
      "2272/2272 - 193s - loss: 0.3684 - accuracy: 0.7294\n",
      "Epoch 130/150\n",
      "2272/2272 - 193s - loss: 0.3554 - accuracy: 0.7339\n",
      "Epoch 131/150\n",
      "2272/2272 - 193s - loss: 0.3573 - accuracy: 0.7334\n",
      "Epoch 132/150\n",
      "2272/2272 - 193s - loss: 0.3659 - accuracy: 0.7267\n",
      "Epoch 133/150\n",
      "2272/2272 - 193s - loss: 0.3676 - accuracy: 0.7307\n",
      "Epoch 134/150\n",
      "2272/2272 - 193s - loss: 0.3665 - accuracy: 0.7298\n",
      "Epoch 135/150\n",
      "2272/2272 - 193s - loss: 0.3498 - accuracy: 0.7375\n",
      "Epoch 136/150\n",
      "2272/2272 - 193s - loss: 0.3431 - accuracy: 0.7403\n",
      "Epoch 137/150\n",
      "2272/2272 - 193s - loss: 0.3505 - accuracy: 0.7358\n",
      "Epoch 138/150\n",
      "2272/2272 - 193s - loss: 0.3471 - accuracy: 0.7393\n",
      "Epoch 139/150\n",
      "2272/2272 - 193s - loss: 0.3421 - accuracy: 0.7417\n",
      "Epoch 140/150\n",
      "2272/2272 - 193s - loss: 0.3435 - accuracy: 0.7435\n",
      "Epoch 141/150\n",
      "2272/2272 - 193s - loss: 0.3403 - accuracy: 0.7433\n",
      "Epoch 142/150\n",
      "2272/2272 - 193s - loss: 0.3374 - accuracy: 0.7440\n",
      "Epoch 143/150\n",
      "2272/2272 - 193s - loss: 0.3516 - accuracy: 0.7398\n",
      "Epoch 144/150\n",
      "2272/2272 - 193s - loss: 0.3330 - accuracy: 0.7475\n",
      "Epoch 145/150\n",
      "2272/2272 - 193s - loss: 0.3643 - accuracy: 0.7364\n",
      "Epoch 146/150\n",
      "2272/2272 - 193s - loss: 0.3217 - accuracy: 0.7547\n",
      "Epoch 147/150\n",
      "2272/2272 - 193s - loss: 0.3331 - accuracy: 0.7498\n",
      "Epoch 148/150\n",
      "2272/2272 - 193s - loss: 0.3347 - accuracy: 0.7489\n",
      "Epoch 149/150\n",
      "2272/2272 - 193s - loss: 0.3287 - accuracy: 0.7494\n",
      "Epoch 150/150\n",
      "2272/2272 - 193s - loss: 0.3303 - accuracy: 0.7509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd4d02ef940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_3D_V56(file[\"data/train/gaf\"][0:10],num_of_classes,lr= 0.00002)\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    verbose=2,\n",
    "    epochs=150,\n",
    "    class_weight=d_class_weights\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LE9cd_A9KwzC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_model1 = path+\"/models/refit/gen/model2\"\n",
    "#model.save(path_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 08:21:55.295816: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-24 08:21:55.319213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 08:21:55.321406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-11-24 08:21:55.321858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 08:21:55.322147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 08:21:55.322533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-11-24 08:21:55.327697: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-24 08:21:55.943746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-24 08:21:55.943779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-11-24 08:21:55.943785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-11-24 08:21:55.944135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 08:21:55.944345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 08:21:55.944523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 08:21:55.944827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9660 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:07:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(path_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 08:22:11.682546: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 29071800000 exceeds 10% of free system memory.\n",
      "2021-11-24 08:24:24.361400: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-24 08:24:24.399129: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3593185000 Hz\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_used' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5841/4144809074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print('Test accuracy: ', results[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(\"Loss: \"f\"{results[0]}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_used' is not defined"
     ]
    }
   ],
   "source": [
    "#Print results and plot confusion matrix\n",
    "\n",
    "#print('Test accuracy: ', results[1])\n",
    "#print(\"Loss: \"f\"{results[0]}\")\n",
    "Y_pred = model_used.predict(X_test, verbose = 2)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "Y_test = np.argmax(y_test, axis=-1)\n",
    "C = confusion_matrix(Y_test, y_pred)\n",
    "# B =np.around((C / C.astype(np.float).sum(axis=1))*100,2)\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "precision,recall,fscore,support=score(Y_test, y_pred,average='macro')\n",
    "print(\"F1 SCORE\",fscore)\n",
    "plot_confusion_matrix_norm(C, appliances, normalize=True)\n",
    "print(classification_report(Y_test, y_pred, target_names=appliances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 5, 100, 100, 1)]  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 5, 100, 100, 16)   800       \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 5, 100, 100, 16)   12560     \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 5, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 5, 50, 50, 16)     2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 5, 50, 50, 16)     2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 5, 25, 25, 16)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 5, 25, 25, 16)     2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 5, 25, 25, 16)     2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 5, 13, 13, 16)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 13, 13, 16)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 5, 13, 13, 16)     2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 5, 13, 13, 16)     2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 5, 2704)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                174144    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22)                374       \n",
      "=================================================================\n",
      "Total params: 201,798\n",
      "Trainable params: 201,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run me!\n",
    "from typing import Tuple, Union, Optional\n",
    "\n",
    "import h5py as h5\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from albumentations import Compose\n",
    "import numpy as np\n",
    "\n",
    "available_modes = {\"train\", \"test\"}\n",
    "available_labels_encoding = {\"hot\", \"smooth\", False}\n",
    "\n",
    "\n",
    "class HDF5ImageGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Just a simple custom Keras HDF5 ImageDataGenerator.\n",
    "    \n",
    "    Custom Keras ImageDataGenerator that generates\n",
    "    batches of tensor images from HDF5 files with (optional) real-time\n",
    "    data augmentation.\n",
    "     \n",
    "    Arguments\n",
    "    ---------\n",
    "    src : str\n",
    "        Path of the hdf5 source file.\n",
    "    X_key : str\n",
    "        Key of the h5 file image tensors dataset.\n",
    "        Default is \"images\".\n",
    "    y_key : str\n",
    "        Key of the h5 file labels dataset.\n",
    "        Default is \"labels\".\n",
    "    classes_key : str\n",
    "        Key of the h5 file dataset containing\n",
    "        the raw classes.\n",
    "        Default is None.\n",
    "    batch_size : int\n",
    "        Size of each batch, must be a power of two.\n",
    "        (16, 32, 64, 128, 256, ...)\n",
    "        Default is 32.\n",
    "    shuffle : bool\n",
    "        Shuffle images at the end of each epoch.\n",
    "        Default is True.\n",
    "    scaler : \"std\", \"norm\" or False\n",
    "        \"std\" mode means standardization to range [-1, 1]\n",
    "        with 0 mean and unit variance.\n",
    "        \"norm\" mode means normalization to range [0, 1].\n",
    "        Default is \"std\".\n",
    "    num_classes : None or int\n",
    "        Specifies the total number of classes\n",
    "        for labels encoding.\n",
    "        Default is None.\n",
    "    labels_encoding : \"hot\", \"smooth\" or False\n",
    "        \"hot\" mode means classic one hot encoding.\n",
    "        \"smooth\" mode means smooth hot encoding.\n",
    "        Default is \"hot\".\n",
    "    smooth_factor : int or float\n",
    "        smooth factor used by smooth\n",
    "        labels encoding.\n",
    "        Default is 0.1.\n",
    "    augmenter : albumentations Compose([]) Pipeline or False\n",
    "        An albumentations transformations pipeline\n",
    "        to apply to each sample.\n",
    "        Default is False.\n",
    "    mode : str \"train\" or \"test\"\n",
    "        Model generator type. \"train\" is used for\n",
    "        fit_generator() and evaluate_generator.\n",
    "        \"test\" is used for predict_generator().\n",
    "        Default is \"train\".\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Turn off scaler (scaler=False) if using the\n",
    "    ToFloat(max_value=255) transformation from\n",
    "    albumentations.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    Example of usage:\n",
    "    ```python\n",
    "    my_augmenter = Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomContrast(limit=0.2, p=0.5),\n",
    "        RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "        RandomBrightness(limit=0.2, p=0.5),\n",
    "        Resize(227, 227, cv2.INTER_AREA)\n",
    "    ])\n",
    "    # Create the generator.\n",
    "    train_gen = HDF5ImageGenerator(\n",
    "        'path/to/my/file.h5',\n",
    "         augmenter=my_augmenter)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        src,\n",
    "        X_key=\"data/gasf\",\n",
    "        y_key=\"labels/gaf\",\n",
    "        classes_key=\"classes/appliances\",\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        scaler=False,\n",
    "        num_classes=9,\n",
    "        labels_encoding=\"hot\",\n",
    "        smooth_factor=0.1,\n",
    "        augmenter=False,\n",
    "        mode=\"train\",\n",
    "    ):\n",
    "\n",
    "        if mode not in available_modes:\n",
    "            raise ValueError('`mode` should be `train` '\n",
    "                             '(fit_generator() and evaluate_generator()) or '\n",
    "                             '`test` (predict_generator(). '\n",
    "                             'Received: %s' % mode)\n",
    "        self.mode = mode\n",
    "\n",
    "        if labels_encoding not in available_labels_encoding:\n",
    "            raise ValueError('`labels_encoding` should be `hot` '\n",
    "                             '(classic binary matrix) or '\n",
    "                             '`smooth` (smooth encoding) or '\n",
    "                             'False (no labels encoding). '\n",
    "                             'Received: %s' % labels_encoding)\n",
    "        self.labels_encoding = labels_encoding\n",
    "\n",
    "        if (self.labels_encoding == \"smooth\") and not (0 < smooth_factor <= 1):\n",
    "            raise ValueError('`smooth` labels encoding '\n",
    "                             'must use a `smooth_factor` '\n",
    "                             '< 0 smooth_factor <= 1')\n",
    "\n",
    "        if augmenter and not isinstance(augmenter, Compose):\n",
    "            raise ValueError('`augmenter` argument '\n",
    "                             'must be an instance of albumentations '\n",
    "                             '`Compose` class. '\n",
    "                             'Received type: %s' % type(augmenter))\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "        self.src: str = src\n",
    "        self.X_key: str = X_key\n",
    "        self.y_key: str = y_key\n",
    "        self.classes_key: str = classes_key\n",
    "        self.batch_size: int = batch_size\n",
    "        self.shuffle: bool = shuffle\n",
    "        self.scaler: bool = scaler\n",
    "        self.num_classes: int = num_classes\n",
    "        self.smooth_factor: float = smooth_factor\n",
    "\n",
    "        self._indices = np.arange(self.__get_dataset_shape(self.X_key, 0))\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Representation of the class.\"\"\"\n",
    "        return f\"{self.__class__.__name__}({self.__dict__!r})\"\n",
    "\n",
    "    def __get_dataset_shape(self, dataset: str, index: int) -> Tuple[int, ...]:\n",
    "        \"\"\"Get an h5py dataset shape.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        dataset : str\n",
    "            The dataset key.\n",
    "        index : int\n",
    "            The dataset index.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ints\n",
    "            A tuple of array dimensions.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\", libver=\"latest\", swmr=True) as file:\n",
    "            return file[dataset].shape[index]\n",
    "\n",
    "    def __get_dataset_items(\n",
    "        self,\n",
    "        indices: np.ndarray,\n",
    "        dataset: Optional[str] = None\n",
    "    ) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"Get an HDF5 dataset items.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        indices : ndarray, \n",
    "            The list of current batch indices.\n",
    "        dataset : (optional) str\n",
    "            The dataset key. If None, returns\n",
    "            a batch of (image tensors, labels).\n",
    "            Defaults to None.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray or a tuple of ndarrays\n",
    "            A batch of samples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\", libver=\"latest\", swmr=True) as file:\n",
    "            if dataset is not None:\n",
    "                return file[dataset][indices]\n",
    "            else:\n",
    "                return (file[self.X_key][indices], file[self.y_key][indices])\n",
    "    \n",
    "    @property\n",
    "    def num_items(self) -> int:\n",
    "        \"\"\"Grab the total number of examples\n",
    "         from the dataset.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of examples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.X_key].shape[0]\n",
    "    \n",
    "    @property \n",
    "    def classes(self) -> list:\n",
    "        \"\"\"Grab \"human\" classes from the dataset.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of the raw classes.\n",
    "        \"\"\"\n",
    "        if self.classes_key is None:\n",
    "            raise ValueError('Canceled. parameter `classes_key` '\n",
    "                             'is set to None.')\n",
    "        \n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.classes_key][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of batches per epochs.\n",
    "        \"\"\"\n",
    "        return int(\n",
    "            np.ceil(\n",
    "                self.__get_dataset_shape(self.X_key, 0) /\n",
    "                float(self.batch_size)))\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_labels_smoothing(batch_y: np.ndarray,\n",
    "                               factor: float) -> np.ndarray:\n",
    "        \"\"\"Applies labels smoothing to the original\n",
    "         labels binary matrix.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        factor : float\n",
    "            Smoothing factor.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y *= 1 - factor\n",
    "        batch_y += factor / batch_y.shape[1]\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    def apply_labels_encoding(\n",
    "            self,\n",
    "            batch_y: np.ndarray,\n",
    "            smooth_factor: Optional[float] = None) -> np.ndarray:\n",
    "        \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "         See Keras to_categorical utils function.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        smooth_factor : (optional) Float\n",
    "            Smooth factor.\n",
    "            Defaults to None.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y = to_categorical(batch_y, num_classes=self.num_classes)\n",
    "\n",
    "        if smooth_factor is not None:\n",
    "            batch_y = self.apply_labels_smoothing(batch_y,\n",
    "                                                  factor=smooth_factor)\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_normalization(batch_X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize the pixel intensities. \n",
    "        \n",
    "        Normalize the pixel intensities to the range [0, 1].\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_X : np.ndarray\n",
    "            Batch of image tensors to be normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A batch of normalized image tensors.\n",
    "        \"\"\"\n",
    "        return batch_X.astype(\"float32\") / 255.0\n",
    "\n",
    "    def __next_batch_test(self, indices: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Generates a batch of test data for the given indices.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            4D tensor (num_samples, height, width, depth).\n",
    "        \"\"\"\n",
    "        # Grab corresponding images from the HDF5 source file.\n",
    "        batch_X = self.__get_dataset_items(indices, self.X_key)\n",
    "\n",
    "        # Shall we rescale features?\n",
    "        if self.scaler:\n",
    "            batch_X = self.apply_normalization(batch_X)\n",
    "\n",
    "        return batch_X\n",
    "\n",
    "    def __next_batch(self,\n",
    "                     indices: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Generates a batch of train/val data for the given indices.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels.\n",
    "        \"\"\"\n",
    "        # Grab samples (tensors, labels) HDF5 source file.\n",
    "        (batch_X, batch_y) = self.__get_dataset_items(indices)\n",
    "\n",
    "        # Shall we apply any data augmentation?\n",
    "        if self.augmenter:\n",
    "            batch_X = np.stack(\n",
    "                [self.augmenter(image=x)[\"image\"] for x in batch_X], axis=0)\n",
    "\n",
    "        # Shall we rescale features?\n",
    "        if self.scaler:\n",
    "            batch_X = self.apply_normalization(batch_X)\n",
    "\n",
    "        # Shall we apply labels encoding?\n",
    "        if self.labels_encoding:\n",
    "            batch_y = self.apply_labels_encoding(\n",
    "                batch_y,\n",
    "                smooth_factor=self.smooth_factor\n",
    "                if self.labels_encoding == \"smooth\" else None,\n",
    "            )\n",
    "\n",
    "        return (batch_X, batch_y)\n",
    "\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"Generates a batch of data for the given index.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the current batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays or ndarray\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels (train) or\n",
    "            a tuple of image tensors (predict).\n",
    "        \"\"\"\n",
    "        # Indices for the current batch.\n",
    "        indices = np.sort(self._indices[index * self.batch_size:(index + 1) *\n",
    "                                        self.batch_size])\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            return self.__next_batch(indices)\n",
    "        else:\n",
    "            return self.__next_batch_test(indices)\n",
    "\n",
    "    def __shuffle_indices(self):\n",
    "        \"\"\"If the shuffle parameter is set to True,\n",
    "         dataset will be shuffled (in-place).\n",
    "         (not available in test 'mode').\n",
    "        \"\"\"\n",
    "        if (self.mode == \"train\") and self.shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Triggered once at the very beginning as well as \n",
    "         at the end of each epoch.\n",
    "        \"\"\"\n",
    "        self.__shuffle_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMej4PvP65qsLng7TnQKWA4",
   "name": "LSTM-gen",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
